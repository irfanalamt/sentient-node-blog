---
title: 'Roboethics'
date: 'September 05 2022'
excerpt: 'The new frontier.'
cover_image: '/images/posts/img7.jpg'
id: 7
---

<img src='/images/posts/img7.jpg' width='310' alt='AI-art' />

As if we didn't have enough to worry about, now we have to worry about whether or not our robots will turn into killer machines and destroy us all. But fear not, my fellow humans, because we have the brilliant Asimov to guide us with his laws of robotics. Or wait, maybe not.

It turns out that [Asimov's laws of robotics](https://en.wikipedia.org/wiki/Three_Laws_of_Robotics), which were supposed to be the ultimate solution for ensuring that robots behave ethically, **aren't really all that great**. For starters, they rely on the assumption that robots are able to understand and make decisions based on ethical principles. Which, let's be real, is not exactly the case for most robots today. Sure, they can probably navigate a factory floor or vacuum your living room, but when it comes to moral dilemmas, they're pretty clueless.

But let's say we do have super advanced robots that are able to understand ethics. There's still the issue of **bias** to consider. AI systems can be biased if the data or the model output is flawed, which can lead to unfair or discriminatory outcomes. And let's not forget that AI systems can be used for nefarious purposes if they are programmed to do so. I mean, just because we can create a robot that can cook the perfect omelette doesn't mean we should trust it with nuclear launch codes.

So what's the solution? Well, it's not exactly clear. Different people have different ideas about what's ethical and what's not, and there's no consensus on where the line should be drawn. Should we give robots the same rights as humans? Should we treat them like property? Should we just pull the plug on the whole AI thing and go back to living in caves? These are all valid questions, and I'm sure there are plenty of other ethical quandaries that I'm not even aware of.

âš¡we'll figure it all out before the robots rise up and enslave us all. Or, you know, before they just do whatever we tell them to do without any regard for the consequences. Either way, it's sure to be a wild ride.

[1][biased-ai](https://www.logically.ai/articles/5-examples-of-biased-ai)

[2][functional-morality](https://go.gale.com/ps/i.do?p=AONE&u=googlescholar&id=GALE|A427482858&v=2.1&it=r&sid=AONE&asid=e03dd0dd)
